{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Chai Time Data Science\nChai Time Data Science shows are series of podcasts hosted by Sanyam Bhutani related to interviews with ML heroes across kaggle, Industry and Research. Contest has been organized marking 1st year anniversary of CTDS.show podcasts. <br>\n\n<b>Podcast related stats and content (subtitles) are provided by the organizers. The goal of this contest is to use these datasets and come up with interesting insights or stories. </b><br>\n\n<b>Judging criteria for the contest - 5 categories: Presentation, Story telling, Visualizations, Insights and Innovation. </b> <br>\n    \nLet us dive in, explore the data, find insights and see whether we could pen a beautiful story out of 1 marvelous sustained perennial year of 85 episodes. Podcasts were made available through Youtube, Spotify, Apple and all other Major podcast directories.<br>\nAlong the way we could get to know ML heroes better through this competition as well as by deciphering podcasts content.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing Packages\n**Importing all the necessary packages as the first step**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly as plty\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\nimport spacy\nimport os\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Loading Datasets & Taking a Peek\nLoading the supplied datasets (description below) in and take a peek. Later we shall explore the need for any external datasets\n* Episodes: Has the stats of all episodes of Chai Time Data Science show\n* Youtube Thumbnail Types: Metadata of youtube thumbnail types used in CTDS show\n* Anchor Thumbnail Types: Metadata of anchor thumbnail types used in CTDS show\n* Description: Description of each episode\n* Cleaned Subtitles: Subtitles of each episode (cleaned version)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/chai-time-data-science/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_episodes = pd.read_csv(f'{path}Episodes.csv',parse_dates=['recording_date','release_date'])\ndf_yt = pd.read_csv(f'{path}YouTube Thumbnail Types.csv')\ndf_anchortn = pd.read_csv(f'{path}Anchor Thumbnail Types.csv')\ndf_desc = pd.read_csv(f'{path}Description.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Lets take a peek at the datasets. Primary gathering info on # of records, missing values and get a feel about the different datasets.</h3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 100)\npd.set_option('display.expand_frame_repr', False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"print('\\033[33m' + 'Episodes Dataset - INFO' + '\\033[0m')\ndf_episodes.info(),\ndf_episodes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"print('\\033[33m' + 'Youtube Thumbnail Types Dataset - INFO' + '\\033[0m')\ndf_yt.info(),\ndf_yt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"print('\\033[33m' + 'Anchor Thumbnail Types Dataset - INFO' + '\\033[0m')\ndf_anchortn.info(),\ndf_anchortn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"print('\\033[33m' + 'Description Dataset - INFO' + '\\033[0m')\ndf_desc.info(),\ndf_desc.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Beginning the Data exploration\n\n# **Questions that ponder**\n* What brings the audience?\n    * Heroes?\n    * Content/format?\n    * Asthetics like thumbnails, tea flavor, recording time, duration etc?\n    * Subscribers?\n    * Timeseries trend?\n* Do viewers sustain?\n* How does podcasts being received across multiple mediums?\n* Lets find some patterns and insights...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* <b>Based on skimming through the available data, we could spot 2 different categories: Content Related (actual content - subtitles) & Non-Content Related (everything else..)\n* Lets being with Non-Content related data..</b>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4 Non-Content Related\n   # 4.1 **Episodes & Show**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('\\033[33m' + 'Episodes Dataset - Exploration stats' + '\\033[0m')\ndf_episodes.describe(include='all').T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What could we find on Episodes\n**Evaluating through youtube, spotify and apple prime stats.**\n(Rounded off)\n* <u>Total</u> \n    * Episodes: 85 with 72 unique heroes\n    * Duration of Videos: 27191 (hrs)\n    * Youtube views: 43616\n    * Spotify streams: 6720\n    * Spotify listeners: 5455\n    * Apple listeners: 1714\n* <u>Average</u>\n    * Episodes/month: 7\n    * Duration of Videos: 3200 (hrs)\n    * Youtube views: 513\n    * Youtube watch duration: 5.3 minutes\n    * Spotify streams: 80\n    * Spotify listeners: 65\n    * Apple listeners: 21\n    * Apple Listen Duration: 29.33 minutes\n    \n\n* Highlight of this entire podcast series is getting audience across multiple platforms, consistency in producing podcasts perenially with ML heroes is not easy by any means. \n* CTDS have given us closer to 2 podcasts per week (1.77 to be exact) in last 1 year, which is monumental.\n* Podcasts have reached over 55k viewers across platforms\n* Youtube is the most preferred and tops the list interms of viewership. Spotify and Apple platforms didn't garner enough viewership with 5455 and 1714 unique listeners respectively. \n* Though apple/spotify podcasts didn't have enough views, they gave CTDS a good audience who watched podcasts for significant duration. <u>While Youtube average watch duration is just 5.3 minutes, apple avg listen duration had a whopping 29.33 minutes. Looks like lesser distractions (or format of the show) for podcasts sets the stage for better audience</u>, but youtube having a mass following garnered more views. \n* Should CTDS concentrate more on reaching podcasts-audio audience where engagement is good or to have a different format for youtube to capitalize viewership and actually being viewed. Why didn't youtube viewers get glued to the videos until the end? Is it due to the format, which is more suited for audio streaming? Lets explore further <br>\n* Initial take looks like - the format of the episodes since being interview series is best suited for audio only podcasts","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h3>We shall start with exploration of episodes on youtube statistics as this medium has significant contribution with views and reaching more audience</h3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.scatter(df_episodes, x='episode_id', y='youtube_subscribers', height=400, title='<b>Episodes Vs New Youtube Subscribers</b>', color='youtube_subscribers',\n             color_continuous_scale='Viridis')\nfig.update_layout(plot_bgcolor='rgb(255,255,255)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.data[0].update(mode='markers+lines')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>youtube subscribers count wasn't iteratively increasing with episodes being released. There is marginal increasing trend between E12 and E44. There are peaks are valleys throughout the journey. Lets explore the trend further </h3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_episodes['yt_subs_cumulative'] = df_episodes['youtube_subscribers'].cumsum()\nfig = make_subplots(rows=4, cols=1, subplot_titles=(\"<b>Youtube Views</b>\", \"<b>Youtube Subscribers</b>\", \"<b>Youtube Subscribers cumulative sum<b>\", \"<b>Episode Duration</b>\"))\n\nfig.append_trace(go.Scatter(name='youtube views', x=df_episodes.episode_id, y=df_episodes.youtube_views), row=1, col=1),\nfig.append_trace(go.Scatter(name='youtube new subscribers', x=df_episodes.episode_id, y=df_episodes.youtube_subscribers), row=2, col=1),\nfig.append_trace(go.Scatter(name='youtube subscribers cumulative sum', x=df_episodes.episode_id, y=df_episodes.yt_subs_cumulative), row=3, col=1)\nfig.append_trace(go.Scatter(name='episode duration', x=df_episodes.episode_id, y=df_episodes.episode_duration), row=4, col=1)\n\nfig.update_layout(height=1200, width=800, legend_orientation=\"h\", plot_bgcolor='rgb(10,10,10)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <u>**Episodes vs youtube subscribers & views**</u>\n* Episodes that had most view rate brought in more subscribers for CTDS show. 3 major peaks (heroes below) were observed - after E1, E27 and E49 and 2 minor peaks after E42 and E43\n    * Jeremy Howard, Parul Pandey, Abhishek Thakur brought in 139, 66, 60 youtube subscribers respectively. Expectations Vs Reality justified :)\n* Episode 25 to 45 seems to be golder with better viewrship and subscribers peak.\n* Episode 2 to 16 seems to be dull phase, with almost flat stats on viewership as well as subscribers.\n* Top 5 viewed episodes got more subscribers in almost same relative order of magnitude.\n* Subscribers increased as we progress over time and there hasn't been any significant downward trend except during fast.ai miniseries, which remained flat. \n* 2 significant observed peaks of subscriber increase were due to top 3 videos that garnered more views that had more than 1500 views\n* Did subcribers brought in more views for episodes that followed those peaks? Seems to be NO based on the trend","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_episodes['release_dofweek'] = df_episodes['release_date'].dt.dayofweek\n\ndf_t = df_episodes.groupby(['release_dofweek'])['youtube_subscribers'].sum().reset_index()\ndf_t1 = df_episodes.groupby(['release_dofweek'])['episode_id'].count().reset_index()\ndf_t2 = df_episodes.groupby(['release_dofweek'])['youtube_views'].sum().reset_index()\nprint(\"Monday is represented as 0 index\")\nprint('\\033[33m' + 'Release Day of Week Vs youtube subscribers' + '\\033[0m')\nprint(df_t)\nprint('\\033[33m' + 'Release Day of Week Vs Episodes count' + '\\033[0m')\nprint(df_t1)\nprint('\\033[33m' + 'Release Day of Week Vs youtube  views' + '\\033[0m')\nprint(df_t2)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nfig = make_subplots(rows=2, cols=1, subplot_titles=(\"Youtube Views\", \"Youtube Subscribers\"))\n\nfig.append_trace(go.Bar(name='youtube views', x=df_episodes.release_dofweek, y=df_episodes.youtube_views), row=1, col=1),\nfig.append_trace(go.Bar(name='youtube subscribers', x=df_episodes.release_dofweek, y=df_episodes.youtube_subscribers), row=2, col=1),\n\nfig.update_layout(height=1000, width=800, title_text=\"<b>Episodes Day of Week (0-Monday) Vs Youtube Stats<b>\", legend_orientation=\"h\", plot_bgcolor='rgb(10,10,10)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Did weekend witnessed more views and subscribers on youtube? Trend is not evident as most views and subscribers rise happened on Sunday (466 subscribers & ~18k views) and Thurday(337 subscribers & ~16.3k views), mostly due to increased # of episodes published during those days.</h3","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4.2 **Heroes**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **<u>Heroes & Gender</u>**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"print('\\033[33m' + 'Episodes that had missing values in heroes column' + '\\033[0m')\ndf_episodes[df_episodes['heroes'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = df_episodes.groupby('heroes_gender').agg({'episode_id':'size', 'youtube_views':'mean'}).reset_index()\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"<b>Gender distribution</b>\", \"<b>Genderwise - youtube avg views/episode</b>\"))\n\nfig.append_trace(go.Bar(name='Gender distribution', x=df.heroes_gender, y=df.episode_id, showlegend=False), row=1, col=1),\nfig.append_trace(go.Bar(name='youtube avg views/episode', x=df.heroes_gender, y=df.youtube_views, showlegend=False), row=1, col=2),\n\nfig.update_layout(barmode='stack', height=500, width=800, legend_orientation=\"h\", plot_bgcolor='rgb(255,255,255)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Out of 74 heroes related podcasts, <u>76 unique heroes were interviewed with repeats from Robert Braco, Edouard Harris and Shivam Bansal. Two interviews were with multiple heroes in same podcast.</u>\n* 11 Missing values in 'heroes' column denotes that those episodes weren't interviews with ML heroes. They were Sanyam's Fastai course summary related, channel intro and AMA episode. They were all shorter duration videos as well exception being the AMA episode.\n* ~88% of heroes were Men and only ~12% were female. Gender bias is evident with the data. Either it could due to market or preference of CTDS or availablity of heroes for interview..\n* <u>Major pointer here - Episodes featuring Female did have very good Average views per episode when compared to episodes featuring male. Note to CTDS show - addressing gender bias would be tangibly positive as well for the channel..</u>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **<u>Location & Nationality</u>**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"l = df_episodes['heroes_location'].value_counts()[:15].index\nv = df_episodes['heroes_location'].value_counts()[:10].values\n\nfig = go.Figure()\nfig.add_trace(go.Pie(labels=l, values=v, textinfo='label+percent', showlegend=False))\nfig.update_layout(height=500, width=600, title_text=\"<b>Heroes Residing Location<b>\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('\\033[33m' + 'Heroes location & nationality' + '\\033[0m')\ndf_episodes.groupby(['heroes_location','heroes_nationality']).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Location of heroes is predominantly USA with ~53% contribution in being part of podcasts, followed by Canada (8.57%), Germany(7.14%), France (4.29%) and UK(4.29%).\n* Locations and Nationals participated in CTDS show good diverse get that covers 19 different countries and 21 different locations.\n* Looking at Nationalities residing in different locations, USA is most diverse country with 8 different nationals (excluding US). Rest of the data is very negligible to call out diverse nationals.\n* Heroes from India & Russia (3 each) are most residing outside their home country.\n* Heroes from Vietnam, Switzerland, Greece, Equador and Africans have been residing outside their home country","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **<u>Category</u>**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize = (20,6), sharex=True)\nsns.countplot(x='category',data=df_episodes,ax=ax[0])\nsns.countplot(x='category',hue='heroes_gender', data=df_episodes,ax=ax[1])\nsns.countplot(x='category',hue='recording_time', data=df_episodes,ax=ax[2])\nax[0].title.set_text('Category count')\nax[1].title.set_text('Category Vs Gender')\nax[2].title.set_text('Category Vs Recording Time')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Heroes from the \"industry\" tops (40%) the podcasts closely followed by \"Kaggle\" (36%) and comparitively lesser researchers (10.5%). \n* Male dominance is pertinent here as well with Kagglers - completely being Male heroes. Within Industry its 18% to 82% Female to Male ratio. \n* <b><u>Better and best - Research field has 33.3% female to 66.67% Male.</u></b><br>\n* Heroes from Industry seem to be convenient with night time recording probably because of geography. Same is true for \"other\" category","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **4.3 Heroes Vs youtube, Apple and Spotify**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_tmp = df_episodes.sort_values(by='heroes')\nfig = px.bar(df_tmp, x='heroes', y='youtube_views', color='youtube_views',color_continuous_scale=[\"red\", \"green\", \"blue\", \"yellow\"],\n              title = '<b>Heroes Vs Youtube Views</b>', height=500)\nfig.update_layout(height=800, plot_bgcolor='rgb(10,10,10)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>* Jeremy Howard's episode had the most views in youtube -> 4502, followed by Parul Pande with 2161 views and Abhishek Thakur with 1528 views<br>\n* As we witnessed in section 4.1 above, those top 3 viewed videos helped significantly to CTDS youtube subscription base as well </h3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_tmp = df_episodes.sort_values(by='youtube_views',ascending=False)\n\n\nfig = go.Figure(data=[\n    go.Bar(name='Spotify listeners', x=df_tmp.heroes, y=df_tmp.spotify_listeners, marker_color='rgb(0, 102, 57)'),\n    go.Bar(name='apple listeners', x=df_tmp.heroes, y=df_tmp.apple_listeners, marker_color='rgb(255, 128, 0)')\n])\nfig.update_layout(barmode='stack', title='<b>heroes vs spotify-apple</b>', legend=dict(x=-.1, y=1.5),plot_bgcolor='rgb(20,20,20)' )\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>\n* Relatively speaking, Spotify/Apple didn't garner enough attention with viewers like youtube, but they had good audience especially Apple podcasts based on the available data<br>\n* Couldn't gather spotify avg listening duration, so couldn't relate the facts, but audio format seems to have worked well with audience listened to them. <u>Apple listen duration is 29.33 minutes when compared to youtube, which is mere 5.3 minutes - 5x more listening time</u>\n* Spotify unique listeners are more (5455) when compared with apple that had 1714 unique listeners <br>\n* Abhishek Thakur's episode had more listeners (456) from Spotify followed by a surprise Andrey Lukyanenko (251) and Ryan Chesler(214) related episodes didn't make it to top 5 list in youtube medium <br>\n* Apple listener segment - Jeremy howard's episode top's the list with 96 unique listeners\n</h3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('\\033[33m' + 'Average Stats grouped by heroes ' + '\\033[0m')\ndf_tmp = df_episodes[['episode_duration','heroes','youtube_views','spotify_streams','spotify_listeners','apple_listeners']].sort_values(by='spotify_listeners', ascending=False)\ndf_tmp.fillna(0).groupby(['heroes']).mean().head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Total videos that had more than avg youtube views:\", len(df_episodes[df_episodes['youtube_views'] > 513]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Out of 85 videos, 29 videos had above the \"average\" youtube views of 513\n\n<h3>Did shorter duration/host-Hero episodes had positive impact on viewership?</h3>\n\n* Host-Hero Episodes aka shorter duration episodes didn't have positive impact (increase) on viewership. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **4.4 Youtube specifics**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<H3><u>Youtube Impressions & Non-Impressions</u></H3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[\n    go.Bar(name='yt impression_views', x=df_episodes.heroes, y=df_episodes.youtube_impression_views),\n    go.Bar(name='yt non impression_views', x=df_episodes.heroes, y=df_episodes.youtube_nonimpression_views)\n])\nfig.update_layout(barmode = 'group', title='<b>heroes vs youtube impressions and non-impressions</b>', legend=dict(x=-.1, y=1.5), plot_bgcolor='rgb(255,255,255)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Total Youtube Impression views:\", df_episodes.youtube_impression_views.sum())\nprint(\"Total Youtube Non Impression views:\", df_episodes.youtube_nonimpression_views.sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>* Non impression views from youtube are more than impression views that indicates CTDS brand - Sanyam's network has driven viewership more than (almost twice) youtube's internal recommendations<br>\n* There are few episodes like Abhishek Thakur, Julian Chaumond, Chip Huyen - where youtube impressions overtook external sources, probably they are so popular and their network could have also contributed to the views..</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**<H3><u>Impact of youtube thumbnails on viewership</u></H3>**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = df_episodes.groupby('youtube_thumbnail_type').agg({'youtube_views':'sum', 'episode_id':'count','youtube_impression_views': 'sum','youtube_nonimpression_views': 'sum'}).reset_index()\nfig = make_subplots(rows=1, cols=4, subplot_titles=(\"youtube views\", \"Episodes count\",\"yt impression views\" , \"yt nonimpression views\"))\n\nfig.append_trace(go.Bar(name='youtube views', x=df.youtube_thumbnail_type, y=df.youtube_views, showlegend=False), row=1, col=1),\nfig.append_trace(go.Bar(name='# of episodes', x=df.youtube_thumbnail_type, y=df.episode_id, showlegend=False), row=1, col=2),\nfig.append_trace(go.Bar(name='youtube impression views', x=df.youtube_thumbnail_type, y=df.youtube_impression_views, showlegend=False), row=1, col=3),\nfig.append_trace(go.Bar(name='youtube nonimpression views', x=df.youtube_thumbnail_type, y=df.youtube_nonimpression_views, showlegend=False), row=1, col=4),\n\nfig.update_layout(barmode='stack', height=400, width=900, title = '<b>Youtube Thumbnail Type  Vs  views-episodes-impressions-nonimpressions</b>', legend_orientation=\"h\", plot_bgcolor='rgb(255,255,255)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Did youtube thumbnails change any audience behavior?\n> *0 - default, 1 - default+custom annotation, 2-custom image+annotation, 3-customer image+ctds branding+Title/tags*\n* Looking at the graph in comparison with episodes, looks like cosmetic professional change of thumbnail didn't have positive impact on episode viewership nor it didn't draw much of youtube impressions as well. Infact episodes with complete CTDS branding of thumbnail had lesser views per episode relatively as we go from default thumbnail.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"** using natsort package in this kernel for couple of sorting needs, the library is handy for natural sorting related tasks**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **5 Content Related**\n# 5.1 Questions from Host Vs Duration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_path = '../input/chai-time-data-science/Cleaned Subtitles/'","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_e27 = pd.read_csv(f'{sub_path}E27.csv')\ndf_e1 = pd.read_csv(f'{sub_path}E1.csv')\ndf_e49 = pd.read_csv(f'{sub_path}E49.csv')\ndf_e33 = pd.read_csv(f'{sub_path}E33.csv')\ndf_e38 = pd.read_csv(f'{sub_path}E38.csv')\ndf_e26 = pd.read_csv(f'{sub_path}E26.csv')\ndf_e60 = pd.read_csv(f'{sub_path}E60.csv')\ndf_e35 = pd.read_csv(f'{sub_path}E35.csv')\ndf_e34 = pd.read_csv(f'{sub_path}E34.csv')\ndf_e25 = pd.read_csv(f'{sub_path}E25.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def questions(df):\n    df_qt = df[df['Text'].str.contains(\"\\?\") & df['Speaker'].str.contains(\"Sanyam Bhutani\")]\n    df_ttemp = df_qt['Text']\n    return df_ttemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = questions(df_e27)\nd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(d)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en', entity=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def word_count(df,e):\n    df['tokens'] = df['Text'].apply(lambda x: nlp(x))\n    df['Word_count'] = [len(token) for token in df.tokens]\n    df_t = df.groupby(['Speaker'])['Word_count'].sum().reset_index()\n    df_t['Episode'] = e\n    return df_t","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def q_count(df):\n    df_qt = df[df['Text'].str.contains(\"\\?\") & df['Speaker'].str.contains(\"Sanyam Bhutani\")]\n    length = len(df_qt)\n    return length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def c_count(df,e):\n    df_ct = df.groupby('Speaker').agg({'char_count':'sum'}).reset_index()\n    df_ct['episode_id'] = e\n#     length = len(df_qt)\n    return df_ct","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install natsort","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ss_list = []\nfor f_name in os.listdir(f'{sub_path}'):\n    ss_list.append(f_name)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from natsort import natsorted\ns_list = natsorted(ss_list)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_qct = pd.DataFrame(columns=['episode', 'q_count'])\nfor i in range(len(s_list)):\n    Episodes = pd.read_csv(f'{sub_path}'+s_list[i])\n    ep_id = s_list[i].split('.')[0]\n    get_df = q_count(Episodes)\n    df_qct = df_qct.append({'episode': ep_id,'q_count': get_df}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_lct = pd.DataFrame(columns=['episode_id', 'Speaker','char_count'])\nfor i in range(len(s_list)):\n    Episodes = pd.read_csv(f'{sub_path}'+s_list[i])\n    ep_id = s_list[i].split('.')[0]\n    Episodes['char_count'] = Episodes['Text'].apply(len)\n    get_df = c_count(Episodes,ep_id)\n    df_lct = df_lct.append(get_df, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_lct['speaker_g'] = df_lct['Speaker'].map({'Sanyam Bhutani': 'Host'})\ndf_lct[\"speaker_g\"].fillna(\"Heroes\", inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<H1> <u>Questions from Host across Episodes </u> </H1>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure(data = go.Scatter(x=df_qct.episode, y=df_qct.q_count, mode='markers+lines'))\nfig.update_layout(title = '<b>Episodes Vs Questions</b>', height=700, width=900, xaxis_title=\"Episodes\", yaxis_title=\"# of questions\",legend_orientation=\"h\", plot_bgcolor='rgb(255,255,255)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<H2>Questions being asked by the host and related inference</H2>\n* Trend in questions being asked by host is almost at the constant mean level of 20/episode, while there is slight dip after E53. Probably based on the comments, suggestions and the learning over time would have brought standardization and maturity in asking just right questions. <br>\n* E69 being the birthday episode related to AMA - question count wass at the peak as expected <br>\n* There were very few episodes with considerable dip in questions.\n    * E74 - there weren't any questions from the host. Verified subtitles as well - there seem to be missing data. Verified by watching related podcasts - data was infact missing. Will try to extract the data here for further analysis later...\n    * E25 and E15 - question count is low. Need to verify whether missing data is genuinely missed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<H1> <u>Episode Introduction Duration and its effect </u> </H1>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Duration calculation\ndf_dur = pd.DataFrame(columns=['episode', 'intro_duration'])\nfor i in range(len(s_list)):\n    Episodes = pd.read_csv(f'{sub_path}'+s_list[i])\n    Episodes['Duration_Sec'] = Episodes['Time'].str.split(':').apply(lambda t: int(t[0]) * 60 + int(t[1]))\n    ep_id = s_list[i].split('.')[0]\n    intro_time = Episodes['Duration_Sec'][1]\n#     get_df = q_count(Episodes)\n    df_dur = df_dur.append({'episode': ep_id,'intro_duration': intro_time}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=2, cols=1, subplot_titles=(\"<b>Episode Intro Duration</b>\", \"<b>Youtube Views</b>\"))\n\nfig.append_trace(go.Scatter(name='<b>Episode Intro Duration</b>', x=df_dur.episode, y=df_dur.intro_duration, marker_color='rgb(0, 102, 57)'), row=1, col=1),\nfig.append_trace(go.Scatter(name='<b>Youtube Views</b>', x=df_episodes.episode_id, y=df_episodes.youtube_views, marker_color='rgb(0, 76, 153)'), row=2, col=1),\n\nfig.update_layout(height=800, width=900, legend_orientation=\"h\", plot_bgcolor='rgb(255,255,255)')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Introduction duration was on a rise in the beginning until E35, later duration got a dip hovering around 150ish seconds. Probably based on the comments, suggestions and the learning over time, introduction was made crisp.\n* How did it correlate with youtube views?\n    * Looks like it didn't have any significant impact or marginally better with views after E23 (over the time subscribers improved as well), in pulling in the audience as after Episode 60 - complete branding and thumbnails have been revamped neither it had positive impact.\n    * Introduction is the key for audience to begin listening to the podcast or viewing youtube videos as they set the stage on what is on the table to stay tuned.\n    * As reiterated earlier, since youtube is visual medium, pictures of some sort that are related to the heroes being displayed along with the intro might look better. Just thoughts.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Flavour of Tea and its effects","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data = [dict(type = 'bar',x = df_episodes.flavour_of_tea, y = df_episodes.youtube_views, mode = 'markers',\n             transforms = [dict(type = 'aggregate',groups = df_episodes.flavour_of_tea,\n                                aggregations = [dict(target = 'y', func = 'avg', enabled = True),])])]\n\nlayout = dict(title = '<b>Tea Flavour vs Mean Youtube views<b>',xaxis = dict(title = 'Tea Flavour'),yaxis = dict(title = 'Mean Youtube views'))\n\n\nfig_dict = dict(data=data,layout=layout)\n\npio.show(fig_dict, validate=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Above visualization represents chai consumed by the host before the episodes against average youtube views/episode. <br>\n* Did it had any effect on the content/audience? Lets find..\n* <u>Episodes where sulemani chai variety was consumed got more avg views per episode with ~1k followed by Ginger Chai with 720 views/episode. Lets explore other parallels that had effect on the viewership or energy level of host across episodes..</u>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.scatter(df_episodes, x = df_episodes.episode_id, y=df_episodes.flavour_of_tea, title='<b>Flavors of Tea across Episodes</b>', color=df_episodes.flavour_of_tea)\nfig.update_layout(plot_bgcolor='rgb(60,60,60)', xaxis={'categoryorder':'category ascending'})\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.update_xaxes(title_text='Episodes')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"yy = df_lct[df_lct['speaker_g'].str.contains(\"Host\")]\nfig = px.bar(yy, x = yy.episode_id, y=yy.char_count, title='<b>Episodes Vs Conversation Text length of Host</b>')\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.update_xaxes(title_text='Episodes')\nfig.update_yaxes(title_text='Host - Text Length')\nfig.update_layout(plot_bgcolor='rgb(255,255,255)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b><u>Tea Flavour Vs Conversation text length of host across episodes</u></b>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tea = pd.merge(df_episodes,yy, how='inner',on='episode_id')\ntea['char_count'] = tea['char_count'].astype(str).astype(int)\ntt = tea.groupby('flavour_of_tea')['char_count'].sum()\ntt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Insights\n* Host's energy level or interaction was more in Episodes E69 (Masala Chai), E63 (Paan Rose Green Tea), E48 (Ginger Chai), E44 (Herbal Tea), E35 (Ginger Chai) <br>\n* After grouping character count of heros by Tea flavours, as found in the table above<br>\n    * Masala Chai tops the energy level with ~181k characters uttered by the host\n    * Closely followed by Ginger Chai with ~178k\n* Host to consume more of Masala and Ginger flavor (could be his favorites) to be more energetic, interactive and bring more liveliness to the podcasts if necessary based on the situation as not all episodes need too much of talking by the host:)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<H1> <u> Word Count of speakers across Episodes </u> <H1>\n    <H3>* (10 Most and Least viewed Episodes)</H3>","execution_count":null},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_wordct = pd.DataFrame()\ndata = word_count(df_e27,'E27')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e1,'E1')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e49,'E49')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e33,'E33')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e38,'E38')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e26,'E26')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e60,'E60')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e35,'E35')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e34,'E34')\ndf_wordct = df_wordct.append(data, ignore_index = True)\ndata = word_count(df_e25,'E25')\ndf_wordct = df_wordct.append(data, ignore_index = True)\n# print(df_wordct)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_e14 = pd.read_csv(f'{sub_path}E14.csv')\ndf_e20 = pd.read_csv(f'{sub_path}E20.csv')\ndf_e7 = pd.read_csv(f'{sub_path}E7.csv')\ndf_e3 = pd.read_csv(f'{sub_path}E3.csv')\ndf_e16 = pd.read_csv(f'{sub_path}E16.csv')\ndf_e10 = pd.read_csv(f'{sub_path}E10.csv')\ndf_e12 = pd.read_csv(f'{sub_path}E12.csv')\ndf_e2 = pd.read_csv(f'{sub_path}E2.csv')\ndf_e8 = pd.read_csv(f'{sub_path}E8.csv')\ndf_e5 = pd.read_csv(f'{sub_path}E5.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df_wordct_low = pd.DataFrame()\ndata = word_count(df_e14,'E14')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\ndata = word_count(df_e20,'E20')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\ndata = word_count(df_e7,'E7')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\ndata = word_count(df_e3,'E3')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\ndata = word_count(df_e16,'E16')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\ndata = word_count(df_e10,'E10')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\ndata = word_count(df_e12,'E12')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\ndata = word_count(df_e2,'E2')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\ndata = word_count(df_e8,'E8')\ndf_wordct_low = df_wordct_low.append(data, ignore_index = True)\n# print(df_wordct_low)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wordct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.bar(df_wordct, x='Episode', y='Word_count', color='Speaker', color_discrete_sequence=px.colors.qualitative.Prism,\n              title = '<b>Top Viewed Episodes - word count host Vs heros</b>', height=500, width=800)\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.update_layout(plot_bgcolor='rgb(0,0,0)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>In regards to Top viewed episodes, Heroes express more and being engaged well than the host, which possibly shows host are opening up gladly and expressing their thoughts, questions are good and other factors. Ratio of word count between host-hero here is 1 : 4.12</h3>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.bar(df_wordct_low, x='Episode', y='Word_count', color='Speaker',color_discrete_sequence=px.colors.qualitative.Prism,\n              title = '<b>Least Viewed Episodes - word count host Vs heros</b>', height=500, width=800)\nfig.update_xaxes(showgrid=False, zeroline=False)\nfig.update_yaxes(showgrid=False, zeroline=False)\nfig.update_layout(plot_bgcolor='rgb(0,0,0)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>In regard to lesser viewed episodes, Host Vs hero ratio of words being spoken is much lesser when compared with top viewed videos. <br>\n    Ratio of word count between host-hero here is just 1 : 2.75</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Insights from subtitles/content of the podcasts\n* <h3>What we infer from Top 10 viewed videos?</h3>\n    * Ratio between word count of Sanyam(host) : Heros is 4.12. This stats show a good interaction between host and heros as heroes were uttering 4x words than the host that represents that heroes were opening up and were engaging more in the podcast. *excluded an outlier - E49 where Sanyam was talking more than the host - ratio was -1.6.<br>\n    * <u>Top viewed video between Jeremy and Sanyam - this word utterance ratio was whopping 5.8</u>. This was the best ratio in the stack and definitely more engaging one with more vocal contribution from the hero of the episode.<br>\n    \n* <h3>What we infer from least 10 viewed videos?</h3>\n    * Ratio between word count of Sanyam(host) : Hero is just 2.75. This stats that heros weren't engaged in the interview much might be due to multiple factors. Will explore more on this regard. <br>\n    * Word count average of the host Sanyam with lowest viewed video (2115 words) is almost the same as with most viewed content (2211 words)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Concluding Statements\n* Appreciation goes to CTDS for hosting such informative, unique podcast series with top ML/Data science researchers across the world\n* Though not exponential, Youtube views and subscriptions are marginally increasing over time.\n* Podcasts looks to be better presented as audio episodes than audio/video (youtube), which is evident from apple/spotify stats vs youtube stats. Former had solid viewership with reference to watch duration though viewership count was less.\n* Youtube videos - better editing / adding exciting visuals / showing some of heroes great work visually like snaps etc might help with engaging the people as one format might not work well for all the medium.\n* Youtube non-impression views are more than impressions (almost 2x), looks like CTDS has got good network and reputation in a circle that has driven non-impression views. To reach masses or larger crowd, organic growth is important.\n* Most viewed videos had better engagement with heroes as ratio of average word count between host and hero is 4.12 whereas with  lowest viewed videos it dropped to just 2.75.\n* Youtube is still better reached to masses, CTDS show need to focus more on visuals, seo, tags, better engaging questions. Views are still not organic as its driven mostly through non impressions than impressions.\n* Masala and Ginger flavour chai seem to be positively impacting host's interaction with the heroes in the podcasts.\n* Better suited podcast mediums - spotify and apple - either marketing/word of mouth will help in getting the audience. Once we get audience they seem to be listening through the episodes more than through youtube.\n* Overall the contribution of CTDS is immense to Machine Learning/Data Science community. Sanyam's release of podcasts is consistent over the year, which shows his dedication. The fact that well respected heroes are willing to give interview to CTDS channel talks about the reputation Sanyam has in AI community.\n\nAll the above are just my humble opinion based on the data and inference. I totally value all the hard work put into running these podcasts. Kudos.\nHopefully this competion will drive the audience to these podcasts exponentially.\n\n<h3>I am not sure whether Sanyam et al would be finding good insights and value from this kernel, but I have learned a lot and will cherish this kaggle kernel as this is my first kaggle submission :)</h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}